@article{Aalen1978,
abstract = {A product limit estimator is suggested for the transition probabilities of a non-homogeneous Markov chain with finitely many states. The estimator is expressed as a product integral and its properties are studied by means of the theory of square integrable martingales.},
author = {Aalen, Odd. O. and Johansen, Soren},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aalen, Johansen - 1978 - An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {0,1,6,censored observations,du,i,limit estimator,markov chains,p,product,q,rl,s,t,transition probabilities,u},
number = {3},
pages = {141--150},
title = {{An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations}},
volume = {5},
year = {1978}
}
@article{Austin2016,
abstract = {Propensity score methods are used to reduce the effects of observed confounding when using observational data to estimate the effects of treatments or exposures. A popular method of using the propensity score is inverse probability of treatment weighting (IPTW). When using this method, a weight is calculated for each subject that is equal to the inverse of the probability of receiving the treatment that was actually received. These weights are then incorporated into the analyses to minimize the effects of observed confounding. Previous research has found that these methods result in unbiased estimation when estimating the effect of treatment on survival outcomes. However, conventional methods of variance estimation were shown to result in biased estimates of standard error. In this study, we conducted an extensive set of Monte Carlo simulations to examine different methods of variance estimation when using a weighted Cox proportional hazards model to estimate the effect of treatment. We considered three variance estimation methods: (i) a na{\"{i}}ve model-based variance estimator; (ii) a robust sandwich-type variance estimator; and (iii) a bootstrap variance estimator. We considered estimation of both the average treatment effect and the average treatment effect in the treated. We found that the use of a bootstrap estimator resulted in approximately correct estimates of standard errors and confidence intervals with the correct coverage rates. The other estimators resulted in biased estimates of standard errors and confidence intervals with incorrect coverage rates. Our simulations were informed by a case study examining the effect of statin prescribing on mortality. {\textcopyright} 2016 The Authors. Statistics in Medicine published by John Wiley & Sons Ltd.},
author = {Austin, Peter C.},
doi = {10.1002/sim.7084},
file = {:/nask.man.ac.uk/home$/Downloads/Austin2016.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Monte Carlo simulations,inverse probability of treatment weighting (IPTW),observational study,propensity score,survival analysis,variance estimation},
number = {30},
pages = {5642--5655},
pmid = {27549016},
title = {{Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis}},
volume = {35},
year = {2016}
}
@article{Austin2020,
abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
author = {Austin, Peter C. and Harrell, Frank E. and van Klaveren, David},
doi = {10.1002/sim.8570},
file = {:P\:/Documents/JournalsandPapers/Austin2019.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {calibration,model validation,random forests,survival analysis,time-to-event model},
number = {21},
pages = {2714--2742},
pmid = {32548928},
title = {{Graphical calibration curves and the integrated calibration index (ICI) for survival models}},
volume = {39},
year = {2020}
}
@article{Austin2022,
abstract = {Assessing calibration—the agreement between estimated risk and observed proportions—is an important component of deriving and validating clinical prediction models. Methods for assessing the calibration of prognostic models for use with competing risk data have received little attention.},
author = {Austin, Peter C. and Putter, Hein and Giardiello, Daniele and van Klaveren, David},
doi = {10.1186/s41512-021-00114-6},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Austin2022.pdf:pdf},
isbn = {4151202100114},
journal = {Diagnostic and Prognostic Research},
keywords = {Calibration,Competing risks,Survival analysis,Time,calibration,competing risks,model validation,random forests,survival analysis,time-to-event model},
number = {1},
publisher = {Diagnostic and Prognostic Research},
title = {{Graphical calibration curves and the integrated calibration index (ICI) for competing risk models}},
volume = {6},
year = {2022}
}
@article{Austin2021,
abstract = {The Fine-Gray subdistribution hazard model has become the default method to estimate the incidence of outcomes over time in the presence of competing risks. This model is attractive because it directly relates covariates to the cumulative incidence function (CIF) of the event of interest. An alternative is to combine the different cause-specific hazard functions to obtain the different CIFs. A limitation of the subdistribution hazard approach is that the sum of the cause-specific CIFs can exceed 1 (100%) for some covariate patterns. Using data on 9479 patients hospitalized with acute myocardial infarction, we estimated the cumulative incidence of both cardiovascular death and non-cardiovascular death for each patient. We found that when using subdistribution hazard models, approximately 5% of subjects had an estimated risk of 5-year all-cause death (obtained by combining the two cause-specific CIFs obtained from subdistribution hazard models) that exceeded 1. This phenomenon was avoided by using the two cause-specific hazard models. We provide a proof that the sum of predictions exceeds 1 is a fundamental problem with the Fine-Gray subdistribution hazard model. We further explored this issue using simulations based on two different types of data-generating process, one based on subdistribution hazard models and other based on cause-specific hazard models. We conclude that care should be taken when using the Fine-Gray subdistribution hazard model in situations with wide risk distributions or a high cumulative incidence, and if one is interested in the risk of failure from each of the different event types.},
author = {Austin, Peter C. and Steyerberg, Ewout W. and Putter, Hein},
doi = {10.1002/sim.9023},
file = {:P\:/Documents/JournalsandPapers/Austin2021.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {cause-specific hazard function,competing risks,cumulative incidence function,subdistribution hazard,survival analysis},
number = {19},
pages = {4200--4212},
pmid = {33969508},
title = {{Fine-Gray subdistribution hazard models to simultaneously estimate the absolute risk of different event types: Cumulative total failure probability may exceed 1}},
volume = {40},
year = {2021}
}
@article{Boulesteix2013,
abstract = {In computational science literature including, e.g., bioinformatics, computational statistics or machine learning, most published articles are devoted to the development of "new methods", while comparison studies are generally appreciated by readers but surprisingly given poor consideration by many journals. This paper stresses the importance of neutral comparison studies for the objective evaluation of existing methods and the establishment of standards by drawing parallels with clinical research. The goal of the paper is twofold. Firstly, we present a survey of recent computational papers on supervised classification published in seven high-ranking computational science journals. The aim is to provide an up-to-date picture of current scientific practice with respect to the comparison of methods in both articles presenting new methods and articles focusing on the comparison study itself. Secondly, based on the results of our survey we critically discuss the necessity, impact and limitations of neutral comparison studies in computational sciences. We define three reasonable criteria a comparison study has to fulfill in order to be considered as neutral, and explicate general considerations on the individual components of a "tidy neutral comparison study". R codes for completely replicating our statistical analyses and figures are available from the companion website http://www.ibe.med.uni-muenchen.de/organisation/mitarbeiter/020_professuren/boulesteix/plea2013. {\textcopyright} 2013 Boulesteix et al.},
author = {Boulesteix, Anne Laure and Lauer, Sabine and Eugster, Manuel J.A.},
doi = {10.1371/journal.pone.0061562},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Boulesteix2013.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pmid = {23637855},
title = {{A Plea for Neutral Comparison Studies in Computational Sciences}},
volume = {8},
year = {2013}
}
@misc{Canty2022,
author = {Canty, Angelo and Ripley, Brian},
title = {{boot: Bootstrap R (S-Plus) Functions}},
url = {https://cran.r-project.org/web/packages/boot/boot.pdf},
year = {2022}
}
@article{Dafni2011,
abstract = {This statistical primer presents the landmark analysis method, exploring its appropriate use and interpretation while recognizing its limitationsThis observational method is used for comparing time-to-event outcome between groups determined during study follow-upThe goal of the landmark method is to estimate in an unbiased way the time-to-event probabilities in each group conditional on the group membership of patients at a specific time point, the landmark timeThe need that led to its development, the impact of the method, and its pros and cons, along with available alternative approaches, are presentedSimulations explore its performance, using realistic parameters from arecent cardiovascular studyAs long as the limitations of the method are recognized and the interpretation of its results clearly reflect their "conditional" nature, landmark analysis, 25 years from its introduction, can still be of value. {\textcopyright} 2011 American Heart Association, Inc.},
author = {Dafni, Urania},
doi = {10.1161/CIRCOUTCOMES.110.957951},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Dafni2011.pdf:pdf},
issn = {19417713},
journal = {Circulation: Cardiovascular Quality and Outcomes},
keywords = {Clinical trials,Observational studies,Prognostic factors,Time-to-event outcome,Time-varying covariate},
number = {3},
pages = {363--371},
pmid = {21586725},
title = {{Landmark analysis at the 25-year landmark point}},
volume = {4},
year = {2011}
}
@article{DeWreede2011,
author = {de Wreede, Liesbeth C and Fiocco, Marta and Putter, Hein},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Wreede, Fiocco, Putter - 2011 - mstate An R Package for the Analysis of Competing Risks and Multi-State Models.pdf:pdf},
journal = {Journal of Statistical Software},
number = {7},
title = {{mstate: An R Package for the Analysis of Competing Risks and Multi-State Models}},
volume = {38},
year = {2011}
}
@misc{EBMT2023,
author = {EBMT},
title = {{Data from the European Society for Blood and Marrow Transplantation}},
url = {https://search.r-project.org/CRAN/refmans/mstate/html/EBMT-data.html},
year = {2023}
}
@article{Heinze2022,
abstract = {Although the biostatistical scientific literature publishes new methods at a very high rate, many of these developments are not trustworthy enough to be adopted by the scientific community. We propose a framework to think about how a piece of methodological work contributes to the evidence base for a method. Similarly to the well-known phases of clinical research in drug development, we define four phases of methodological research. These four phases cover (I) providing logical reasoning and proofs, (II) providing empirical evidence, first in a narrow target setting, then (III) in an extended range of settings and for various outcomes, accompanied by appropriate application examples, and (IV) investigations that establish a method as sufficiently well-understood to know when it is preferred over others and when it is not. We provide basic definitions of the four phases but acknowledge that more work is needed to facilitate unambiguous classification of studies into phases. Methodological developments that have undergone all four proposed phases are still rare, but we give two examples with references. Our concept rebalances the emphasis to studies in phase III and IV, i.e., carefully planned methods comparison studies and studies that explore the empirical properties of existing methods in a wider range of problems.},
archivePrefix = {arXiv},
arxivId = {2209.13358},
author = {Heinze, Georg and Boulesteix, Anne-Laure and Kammer, Michael and Morris, Tim P. and White, Ian R.},
doi = {10.1002/bimj.202200222},
eprint = {2209.13358},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Heinze2023.pdf:pdf},
issn = {15214036},
keywords = {2 institute for medical,biometry and epidemiology,information,ludwig-maximilians university of,processing},
number = {December 2022},
pages = {1--8},
title = {{Phases of methodological research in biostatistics - building the evidence base for new methods}},
url = {http://arxiv.org/abs/2209.13358},
year = {2022}
}
@incollection{Hernan2020,
address = {Boca Raton},
author = {Hernan, MA and Robins, JM},
booktitle = {Causal Inference: What If},
chapter = {12.2},
publisher = {Chapman & Hall/CRC},
title = {{12.2 Estimating IP weights via modeling}},
year = {2020}
}
@article{Le-Rademacher2018,
abstract = {Background/aims: The goal of this article is to illustrate the utility of multi-state models in cancer clinical trials. Our specific aims are to describe multi-state models and how they differ from standard survival methods, to illustrate how multi-state models can facilitate deeper understanding of the treatment effect on multiple paths along the disease process that patients could experience in cancer clinical trials, to explain the differences between multi-state models and time-dependent Cox models, and to briefly describe available software to conduct such analyses. Methods: Data from 717 newly diagnosed acute myeloid leukemia patients who enrolled in the CALGB 10603 trial were used as an illustrative example. The current probability-in-state was estimated using the Aalen–Johansen estimator. The restricted mean time in state was calculated as the area under the probability-in-state curves. Cox-type regression was used to evaluate the effect of midostaurin on the various clinical paths. Simulation was conducted using a newly constructed shiny application. All analyses were performed using the R software. Results: Multi-state model analyses of CALGB 10603 suggested that the overall improvement in survival with midostaurin seen in the primary analysis possibly resulted from a higher complete remission rate in combination with a lower risk of relapse and of death after complete remission in patients treated with midostaurin. Simulation results, in a three-state illness-death without recovery model, demonstrate that multi-state models and time-dependent Cox models evaluate treatment effects from different frameworks. Conclusion: Multi-state models allow detailed evaluation of treatment effects in complex clinical trial settings where patients can experience multiple paths between study enrollment and the final outcome. Multi-state models can be used as a complementary tool to standard survival analyses to provide deeper insights to the effects of treatment in trial settings with complex disease process.},
author = {Le-Rademacher, Jennifer G. and Peterson, Ryan A. and Therneau, Terry M. and Sanford, Ben L. and Stone, Richard M. and Mandrekar, Sumithra J.},
doi = {10.1177/1740774518789098},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Le-Rademacher.pdf:pdf},
issn = {17407753},
journal = {Clinical Trials},
keywords = {Multi-state model,cancer,clinical trials,survival analysis,time-to-event data},
number = {5},
pages = {489--498},
pmid = {30035644},
title = {{Application of multi-state models in cancer clinical trials}},
volume = {15},
year = {2018}
}
@article{Lintu2022,
abstract = {Background: Understanding the progression of kidney disease is of great interest among clinicians. The multi-state model is an adequate tool to model the effects of covariates that influence the onset, progression, and regression of kidney function. Objective: The goal of the present study is to propose a stochastic model for kidney disease progression and to demonstrate the application of the same. Methodology: We proposed a semi-parametric continuous time homogeneous multi-state Markov model for the kidney disease progression data obtained from a retrospective study of 225 patients prescribed with colistin (a re-emerging antibiotic) in a tertiary care hospital in coastal Karnataka. Different stages of kidney disease were defined based on the Kidney Disease Improving Global Outcome (KDIGO) score. The model consists of three transient states, and an absorbing state death. Covariate effects on the bidirectional transition rates were estimated using the multi-state model. Results: We used the data of 225 patients to see their kidney disease progression. All the patients were under colistin therapy. The median length of hospital stay was 21 days. A total of 83 (36.89%) patients died in the hospital. The prognostic factors such as gender, hypertension, sepsis, and surgery are significant factors affecting kidney disease in different stages. Conclusion: The findings of the study will be useful for public health policymakers to implement the policies and treatment plans to improve the survival of the patients. Moreover, modelling the disease progression helps in understanding the expected burden of the disease.},
author = {Lintu, M. K. and Shreyas, K. M. and Kamath, Asha},
doi = {10.1016/j.cegh.2021.100946},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Lintu2022.pdf:pdf},
issn = {22133984},
journal = {Clinical Epidemiology and Global Health},
keywords = {Disease progression,Intermediate events,Kidney disease,Multi-state model,Transition intensity},
number = {December 2021},
pages = {100946},
publisher = {Elsevier B.V.},
title = {{A multi-state model for kidney disease progression}},
url = {https://doi.org/10.1016/j.cegh.2021.100946},
volume = {13},
year = {2022}
}
@article{Masia2017,
author = {Masia, Mar and Padilla, Sergio and Moreno, Santiago and Barber, Xavier and Iribarren, Jose A and Romero, Jorge and LIST, NEED TO FINISH AUTHOR},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Masia2017.pdf:pdf},
isbn = {1111111111},
journal = {PLoS ONE},
pages = {1--16},
title = {{Prediction of long-term outcomes of HIV- infected patients developing non-AIDS events using a multistate approach}},
volume = {112},
year = {2017}
}
@article{Pullenayegum2016,
abstract = {Background:The use of standard statistical methods in the medical literature has been studied extensively; however, the adoption of new methods has received less attention. We sought to understand (i) whether there is a perception that new methods are underused, (ii) what the barriers to use of new methods are, (iii) what dissemination activities are used, and (iv) user preferences for learning about new methods. Methods:We conducted a cross-sectional survey of members of the Statistical Society of Canada (SSC) and of principal investigators (knowledge-users) funded by the Canadian Institutes of Health Research (CIHR). Results: There were 157 CIHR respondents (14% response rate), and 39 respondents were statisticians from the Statistical Society of Canada. Seventy percent of CIHR respondents and 82% of statisticians felt that new developments were under-used. Barriers to use of new methods included lack of access to the necessary expertise (selected by over 90% of respondents), lack of suitable software (selected by 81% of statisticians), and lack of time to implement new methods (selected by 78% of statisticians). Greater access to statistical colleagues with an interest in collaboration and availability of software to implement new methods were the top-rated preferences among knowledge-users. Conclusions: There was a clear perception among all respondents that new statistical methods are underused. Encouraging statistical methodologists to develop a knowledge translation plan for improved dissemination and uptake, placing greater value on the role of the statistical collaborator in research, and providing software alongside new methods may improve the use of newly developed statistical methods.},
author = {Pullenayegum, Eleanor M. and Platt, Robert W. and Barwick, Melanie and Feldman, Brian M. and Offringa, Martin and Thabane, Lehana},
doi = {10.1002/sim.6633},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Pullenayegum2015.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Biostatistics,Collaboration,Knowledge,Translation},
number = {6},
pages = {805--818},
pmid = {26307183},
title = {{Knowledge translation in biostatistics: A survey of current practices, preferences, and barriers to the dissemination and uptake of new statistical methods}},
volume = {35},
year = {2016}
}
@article{Putter2007,
abstract = {Standard survival data measure the time span from some time origin until the occurrence of one type of event. If several types of events occur, a model describing progression to each of these competing risks is needed.Multi-state models generalize competing risksmodels by also describing transitions to intermediate events. Methods to analyze such models have been developed over the last two decades. Fortunately, most of the analyzes can be performed within the standard statistical packages, but may require some extra effort with respect to data preparation and programming. This tutorial aims to review statistical methods for the analysis of competing risks and multi-state models. Although some conceptual issues are covered, the emphasis is on practical issues like data preparation, estimation of the effect of covariates, and estimation of cumulative incidence functions and state and transition probabilities. Examples of analysis with standard software are shown. Copyright q 2006 John Wiley & Sons, Ltd.},
author = {Putter, H and Fiocco, M and Geskus, R. B.},
doi = {10.1002/sim},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Putter, Fiocco, Geskus - 2007 - Tutorial in biostatistics Competing risks and multi-state models.pdf:pdf},
isbn = {2007090091480},
journal = {Statistics in medicine},
keywords = {competing risks,multi-state model,prediction,prognostic factors,survival analysis},
number = {11},
pages = {2389--2430},
pmid = {19455509},
title = {{Tutorial in biostatistics: Competing risks and multi-state models}},
volume = {26},
year = {2007}
}
@article{Putter2018,
abstract = {The topic non-parametric estimation of transition probabilities in non-Markov multi-state models has seen a remarkable surge of activity recently. Two recent papers have used the idea of subsampling in this context. The first paper, by de U{\~{n}}a {\'{A}}lvarez and Meira-Machado, uses a procedure based on (differences between) Kaplan–Meier estimators derived from a subset of the data consisting of all subjects observed to be in the given state at the given time. The second, by Titman, derived estimators of transition probabilities that are consistent in general non-Markov multi-state models. Here, we show that the same idea of subsampling, used in both these papers, combined with the Aalen–Johansen estimate of the state occupation probabilities derived from that subset, can also be used to obtain a relatively simple and intuitive procedure which we term landmark Aalen–Johansen. We show that the landmark Aalen–Johansen estimator yields a consistent estimator of the transition probabilities in general non-Markov multi-state models under the same conditions as needed for consistency of the Aalen–Johansen estimator of the state occupation probabilities. Simulation studies show that the landmark Aalen–Johansen estimator has good small sample properties and is slightly more efficient than the other estimators.},
author = {Putter, Hein and Spitoni, Cristian},
doi = {10.1177/0962280216674497},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Putter2016.pdf:pdf},
isbn = {0962280216},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Markov assumption,Multi-state model,transition probability},
number = {7},
pages = {2081--2092},
pmid = {29846146},
title = {{Non-parametric estimation of transition probabilities in non-Markov multi-state models: The landmark Aalen–Johansen estimator}},
volume = {27},
year = {2018}
}
@article{Putter2006,
abstract = {An important aim in clinical studies in oncology is to study how treatment and prognostic factors influence the course of disease of a patient. Typically in these trials, besides overall survival, also other endpoints such as locoregional recurrence or distant metastasis are of interest. Most commonly in these situations, Cox regression models are applied for each of these endpoints separately or to composite endpoints such as disease-free survival. These approaches however fail to give insight into what happens to a patient after a first event. We re-analyzed data of 2795 patients from a breast cancer trial (EORTC 10854) by applying a multi-state model, with local recurrence, distant metastasis, and both local recurrence and distant metastasis as transient states and death as absorbing state. We used an approach where the clock is reset on entry of a new state. The influence of prognostic factors on each of the transition rates is studied, as well as the influence of the time at which intermediate events occur. The estimated transition rates between the states in the model are used to obtain predictions for patients with a given history. Formulas are developed and illustrated for these prediction probabilities for the clock reset approach. {\textcopyright} 2006 WILEY-VCH Verlag GmbH & Co. KGaA,.},
author = {Putter, Hein and {Van Hage}, Jos Der and {De Bock}, Geertruida H. and Elgalta, Rachid and {Van De Velde}, Cornelis J.H.},
doi = {10.1002/bimj.200510218},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Putter2006.pdf:pdf},
issn = {03233847},
journal = {Biometrical Journal},
keywords = {Multi-state model,Prediction,Prognostic factors,Survival analysis},
number = {3},
pages = {366--380},
pmid = {16845902},
title = {{Estimation and prediction in a multi-state model for breast cancer}},
volume = {48},
year = {2006}
}
@article{Sperrin2022,
abstract = {Clinical prediction models must be appropriately validated before they can be used. While validation studies are sometimes carefully designed to match an intended population/setting of the model, it is common for validation studies to take place with arbitrary datasets, chosen for convenience rather than relevance. We call estimating how well a model performs within the intended population/setting “targeted validation”. Use of this term sharpens the focus on the intended use of a model, which may increase the applicability of developed models, avoid misleading conclusions, and reduce research waste. It also exposes that external validation may not be required when the intended population for the model matches the population used to develop the model; here, a robust internal validation may be sufficient, especially if the development dataset was large.},
author = {Sperrin, Matthew and Riley, Richard D. and Collins, Gary S. and Martin, Glen P.},
doi = {10.1186/s41512-022-00136-8},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Sperrin2022.pdf:pdf},
issn = {2397-7523},
journal = {Diagnostic and Prognostic Research},
keywords = {Clinical prediction model,Generalisability,Validation,clinical prediction model,generalisability,validation},
number = {1},
pages = {4--9},
publisher = {BioMed Central},
title = {{Targeted validation: validating clinical prediction models in their intended population and setting}},
url = {https://doi.org/10.1186/s41512-022-00136-8},
volume = {6},
year = {2022}
}
@article{Steyerberg2016,
abstract = {Chronic alcohol use and abuse result in widespread changes to gene expression, some of which contribute to the development of alcohol use disorders (AUD). Gene expression is, in part, controlled by a group of regulatory systems often referred to as epigenetic factors, which includes, among other mechanisms, chemical marks made on the histone proteins around which genomic DNA is wound to form chromatin, and on nucleotides of the DNA itself. In particular, alcohol has been shown to perturb the epigenetic machinery, leading to changes in gene expression and cellular functions characteristic of AUD and, ultimately, to altered behavior. DNA modifications in particular are seeing increasing research in the context of alcohol use and abuse. To date, studies of DNA modifications in AUD have primarily looked at global methylation profiles in human brain and blood, gene-specific methylation profiles in animal models, methylation changes associated with prenatal ethanol exposure, and the potential therapeutic abilities of DNA methyltransferase inhibitors. Future studies may be aimed at identifying changes to more recently discovered DNA modifications, utilizing new methods to discriminate methylation profiles between cell types and clarifying how alcohol influences the methylomes of cell type populations and how this may affect downstream processes. These studies and more in-depth probing of DNA methylation will be key to determining whether DNA-level epigenetic regulation plays a causative role in AUD and can thus be targeted for treatment of the disorder. Keywords},
author = {Steyerberg, Ewout W and {Harrell Jr}, Frank E},
doi = {10.1016/j.jclinepi.2015.04.005},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Steyerberg2016.pdf:pdf},
journal = {Journal of Clinical Epidemiology},
keywords = {determination,endothelium,estrogen,estrogen receptors,protein crystallography,protein data bank,r -factor,resolution,restraints,structure,structure interpretation,structure quality,structure refinement,structure validation,vascular smooth muscle},
pages = {245--247},
title = {{Prediction models need appropriate internal, internal-external, and external validation}},
volume = {69},
year = {2016}
}
@article{VanCalster2019,
abstract = {Background: The assessment of calibration performance of risk prediction models based on regression or more flexible machine learning algorithms receives little attention. Main text: Herein, we argue that this needs to change immediately because poorly calibrated algorithms can be misleading and potentially harmful for clinical decision-making. We summarize how to avoid poor calibration at algorithm development and how to assess calibration at algorithm validation, emphasizing balance between model complexity and the available sample size. At external validation, calibration curves require sufficiently large samples. Algorithm updating should be considered for appropriate support of clinical practice. Conclusion: Efforts are required to avoid poor calibration when developing prediction models, to evaluate calibration when validating models, and to update models when indicated. The ultimate aim is to optimize the utility of predictive analytics for shared decision-making and patient counseling.},
author = {{Van Calster}, Ben and McLernon, David J. and {Van Smeden}, Maarten and Wynants, Laure and Steyerberg, Ewout W. and Bossuyt, Patrick and Collins, Gary S. and MacAskill, Petra and Moons, Karel G.M. and Vickers, Andrew J.},
doi = {10.1186/s12916-019-1466-7},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/vanCalster2019.pdf:pdf},
issn = {17417015},
journal = {BMC Medicine},
keywords = {Calibration,Heterogeneity,Model performance,Overfitting,Predictive analytics,Risk prediction models},
number = {1},
pages = {1--7},
pmid = {31842878},
publisher = {BMC Medicine},
title = {{Calibration: The Achilles heel of predictive analytics}},
volume = {17},
year = {2019}
}
@article{VanCalster2016,
abstract = {Objective Calibrated risk models are vital for valid decision support. We define four levels of calibration and describe implications for model development and external validation of predictions. Study Design and Setting We present results based on simulated data sets. Results A common definition of calibration is "having an event rate of R% among patients with a predicted risk of R%," which we refer to as "moderate calibration." Weaker forms of calibration only require the average predicted risk (mean calibration) or the average prediction effects (weak calibration) to be correct. "Strong calibration" requires that the event rate equals the predicted risk for every covariate pattern. This implies that the model is fully correct for the validation setting. We argue that this is unrealistic: the model type may be incorrect, the linear predictor is only asymptotically unbiased, and all nonlinear and interaction effects should be correctly modeled. In addition, we prove that moderate calibration guarantees nonharmful decision making. Finally, results indicate that a flexible assessment of calibration in small validation data sets is problematic. Conclusion Strong calibration is desirable for individualized decision support but unrealistic and counter productive by stimulating the development of overly complex models. Model development and external validation should focus on moderate calibration.},
author = {{Van Calster}, Ben and Nieboer, Daan and Vergouwe, Yvonne and {De Cock}, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
doi = {10.1016/j.jclinepi.2015.12.005},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Calster et al. - 2016 - A calibration hierarchy for risk models was defined From utopia to empirical data.pdf:pdf},
issn = {18785921},
journal = {Journal of Clinical Epidemiology},
keywords = {Calibration,Decision curve analysis,External validation,Loess,Overfitting,Risk prediction models},
pages = {167--176},
pmid = {26772608},
publisher = {Elsevier Inc},
title = {{A calibration hierarchy for risk models was defined: From utopia to empirical data}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2015.12.005},
volume = {74},
year = {2016}
}
@article{VanHoorde2015,
abstract = {Calibration refers to the reliability of the predicted risks, i.e. whether the predicted risks correspond to observed probabilities. In medical applications this is important because treatment decisions often rely on the estimated risk of disease. The aim of this paper is to present generic tools to assess the calibration of multiclass risk models.We describe a calibration framework based on a vector spline multinomial logistic regression model. This framework can be used to generate calibration plots and calculate the estimated calibration index (ECI) to quantify lack of calibration. We illustrate these tools in relation to risk models used to characterize ovarian tumors. The outcome of the study is the surgical stage of the tumor when relevant and the final histological outcome, which is divided into five classes: benign, borderline malignant, stage I, stage II-IV, and secondary metastatic cancer. The 5909 patients included in the study are randomly split into equally large training and test sets. We developed and tested models using the following algorithms: logistic regression, support vector machines, k nearest neighbors, random forest, naive Bayes and nearest shrunken centroids.Multiclass calibration plots are interesting as an approach to visualizing the reliability of predicted risks. The ECI is a convenient tool for comparing models, but is less informative and interpretable than calibration plots. In our case study, logistic regression and random forest showed the highest degree of calibration, and the naive Bayes the lowest.},
author = {{Van Hoorde}, K. and {Van Huffel}, S. and Timmerman, D. and Bourne, T. and {Van Calster}, B.},
doi = {10.1016/j.jbi.2014.12.016},
file = {:P\:/Documents/JournalsandPapers/vanHoorde2015.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Calibration,Logistic regression,Machine learning,Multiclass,Probability estimation,Risk models},
pages = {283--293},
pmid = {25579635},
publisher = {Elsevier Inc.},
title = {{A spline-based tool to assess and visualize the calibration of multiclass risk predictions}},
url = {http://dx.doi.org/10.1016/j.jbi.2014.12.016},
volume = {54},
year = {2015}
}
@article{VanHoorde2014,
author = {{Van Hoorde}, Kirsten and Vergouwe, Yvonne and Timmerman, Dirk and {Van Huffel}, Sabine and Steyerberg, W and {Van Calster}, Ben},
doi = {10.1002/sim.6114},
journal = {Statistics in Medicine},
number = {15},
pages = {2585--2596},
title = {{Assessing calibration of multinomial risk prediction models}},
volume = {33},
year = {2014}
}
@article{Houwelingen2007,
author = {van Houwelingen, Hans C.},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/vanHouwelingen2007.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {dependent covariates,landmark analysis,landmarking,pseudo-partial likelihood,survival analysis,tim,time-varying effects},
number = {1},
pages = {70--85},
title = {{Dynamic Prediction by Landmarking in Event History Analysis}},
volume = {34},
year = {2007}
}
@article{VanSmeden2021,
abstract = {Clinical prediction models play an increasingly important role in contemporary clinical care, by informing healthcare professionals, patients and their relatives about outcome risks, with the aim to facilitate (shared) medical decision making and improve health outcomes. Diagnostic prediction models aim to calculate an individual's risk that a disease is already present, whilst prognostic prediction models aim to calculate the risk of particular heath states occurring in the future. This article serves as a primer for diagnostic and prognostic clinical prediction models, by discussing the basic terminology, some of the inherent challenges, and the need for validation of predictive performance and the evaluation of impact of these models in clinical care.},
author = {van Smeden, Maarten and Reitsma, Johannes B. and Riley, Richard D. and Collins, Gary S. and Moons, Karel GM},
doi = {10.1016/j.jclinepi.2021.01.009},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Smeden et al. - 2021 - Clinical prediction models diagnosis versus prognosis.pdf:pdf},
issn = {18785921},
journal = {Journal of Clinical Epidemiology},
keywords = {Diagnostic,Model impact,Model performance,Prediction models,Prognostic,Reporting guidelines,Validation},
pages = {142--145},
pmid = {33775387},
publisher = {Elsevier},
title = {{Clinical prediction models: diagnosis versus prognosis}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2021.01.009},
volume = {132},
year = {2021}
}
@book{Yee2015,
author = {Yee, Thomas W.},
doi = {10.1007/978-1-4939-2818-7},
edition = {1},
isbn = {978-1-4939-4198-8},
publisher = {Springer New York, NY},
title = {{Vector Generalized Linear and Additive Models}},
url = {https://link.springer.com/book/10.1007/978-1-4939-2818-7},
year = {2015}
}
