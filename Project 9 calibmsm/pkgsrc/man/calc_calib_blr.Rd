% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calc_calib_blr.R
\name{calc_calib_blr}
\alias{calc_calib_blr}
\title{Create data for calibration curves using a binary logistic regression
framework with inverse probability of censoring weights}
\usage{
calc_calib_blr(
  data.mstate,
  data.raw,
  j,
  s,
  t.eval,
  tp.pred,
  curve.type = "rcs",
  rcs.nk = 3,
  loess.span,
  loess.degree,
  weights = NULL,
  w.covs,
  w.landmark.type = "state",
  w.max = 10,
  w.stabilised = FALSE,
  w.max.follow = NULL,
  CI = FALSE,
  CI.R.boot,
  data.pred.plot = NULL,
  transitions.out = NULL
)
}
\arguments{
\item{data.mstate}{Validation data in \code{msdata} format.}

\item{data.raw}{Validation data in data.frame (one row per individual).}

\item{j}{Landmark state at which predictions were made}

\item{s}{Landmark time at which predictions were made}

\item{t.eval}{Follow up time at which calibration is to be assessed}

\item{tp.pred}{Matrix of predicted transition probabilities at time t.eval, if in state j at time s. There must be a seperate column for the predicted transition probabilities into every state, even if these predicted transition probabilities are 0.}

\item{curve.type}{Whether calibration curves are estimated using restricted cubic splines ('rcs') or loess smoothers ('loess')}

\item{rcs.nk}{Number of knots when curves are estimated using restricted cubic splines}

\item{loess.span}{Span when curves are estimated using loess smoothers}

\item{loess.degree}{Degree when curves are estimated using loess smoothers}

\item{weights}{Vector of inverse probability of censoring weights}

\item{w.covs}{Character vector of variable names to adjust for when calculating inverse probability of censoring weights}

\item{w.landmark.type}{Whether weights are estimated in all individuals uncensored at time s ('all') or only in individuals uncensored and in state j at time s ('state')}

\item{w.max}{Maximum bound for inverse probability of censoring weights}

\item{w.stabilised}{Indicates whether inverse probability of censoring weights should be stabilised or not}

\item{w.max.follow}{Maximum follow up for model calculating inverse probability of censoring weights. Reducing this to \code{t.eval} + 1 may aid in the proportional hazards assumption being met in this model.}

\item{CI}{Size of confidence intervals as a \%}

\item{CI.R.boot}{Number of bootstrap replicates when estimating the confidence interval for the calibration curve}

\item{data.pred.plot}{Data frame or matrix of predicted risks for each possible transition over which to plot the calibration curves. Must have one column for every possible transition.}

\item{transitions.out}{Transitions for which to calculate calibration curves. Will do all possible transitions if left as NULL.}
}
\description{
Creates the underlying data for the calibration plots. Observed event
probabilities at time \code{t.eval} are estimated for inputted predicted
transition probabilities \code{tp.pred} out of state \code{j} at time \code{s}.
\code{calc_calib_blr} estimates calibration curves using a binary logistic
framework in combination with landmarking and inverse probability of
censoring weights. A choice between restricted cubic splines and loess
smoothers for estimating the calibration curve can be made using \code{curve.type}.

Two datasets for the same cohort of inidividuals must be provided. A \code{msdata}
format dataset generated using the \code{mstate} package. A \code{data.frame} with one
row per individual, relevant variables for estimating the weights, and a time
until censoring varaible (\code{dtcens}) and indicator (\code{dtcens.s}). Weights are
estimated using a cox-proportional hazard model and assuming linear
functional form of the variables defined in \code{w.covs}. We urge users to
specify their own model for estimating the weights. Confidence intervals for
the calibration curves can be estimated using bootstrapping. This procedure
uses the internal method for estimating weights, we therefore encourage
users to specify their own bootstrapping procedure, which incorporates their
own model for estimating the weights. Details on how to do this are provided
in the vignette.
}
